{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Autoimport wherept.py:\n",
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport wherept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1061d0970>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "import pandas as pd\n",
    "from torchview import draw_graph\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlage\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/lage/Development/woher/gen3/wandb/run-20231203_184956-iemsn0l4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lage/woher/runs/iemsn0l4' target=\"_blank\">ethereal-music-38</a></strong> to <a href='https://wandb.ai/lage/woher' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lage/woher' target=\"_blank\">https://wandb.ai/lage/woher</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lage/woher/runs/iemsn0l4' target=\"_blank\">https://wandb.ai/lage/woher/runs/iemsn0l4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(project=\"woher\", job_type=\"transformer-playground\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   1 of 1 files downloaded.  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>Soldeu</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>El Tarter</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>Sant Julia de Loria</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ordino</td>\n",
       "      <td>Ordino</td>\n",
       "      <td>42.55623</td>\n",
       "      <td>1.53319</td>\n",
       "      <td>AD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name            asciiname  latitude  longitude country_code\n",
       "0               Soldeu               Soldeu  42.57688    1.66769           AD\n",
       "1            El Tarter            El Tarter  42.57952    1.65362           AD\n",
       "2  Sant Julià de Lòria  Sant Julia de Loria  42.46372    1.49129           AD\n",
       "3       Pas de la Casa       Pas de la Casa  42.54277    1.73361           AD\n",
       "4               Ordino               Ordino  42.55623    1.53319           AD"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = run.use_artifact(\"woher/cleaned-cities:latest\").get(\"clean\")\n",
    "df_raw = dataset.get_dataframe()\n",
    "df_raw.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "TARGET_COL = \"asciiname\"\n",
    "START_CHAR = \"<\"\n",
    "END_CHAR = \">\"\n",
    "PADDING_CHAR = \"#\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary length: 61\n",
      "Vocabulary:  #'-.1<>ABCDEFGHIJKLMNOPQRSTUVWXYZ`abcdefghijklmnopqrstuvwxyz\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>target_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>&lt;Soldeu&gt;######################################...</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>&lt;El Tarter&gt;###################################...</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sant Julià de Lòria</td>\n",
       "      <td>&lt;Sant Julia de Loria&gt;#########################...</td>\n",
       "      <td>42.46372</td>\n",
       "      <td>1.49129</td>\n",
       "      <td>AD</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pas de la Casa</td>\n",
       "      <td>&lt;Pas de la Casa&gt;##############################...</td>\n",
       "      <td>42.54277</td>\n",
       "      <td>1.73361</td>\n",
       "      <td>AD</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ordino</td>\n",
       "      <td>&lt;Ordino&gt;######################################...</td>\n",
       "      <td>42.55623</td>\n",
       "      <td>1.53319</td>\n",
       "      <td>AD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name                                          asciiname  \\\n",
       "0               Soldeu  <Soldeu>######################################...   \n",
       "1            El Tarter  <El Tarter>###################################...   \n",
       "2  Sant Julià de Lòria  <Sant Julia de Loria>#########################...   \n",
       "3       Pas de la Casa  <Pas de la Casa>##############################...   \n",
       "4               Ordino  <Ordino>######################################...   \n",
       "\n",
       "   latitude  longitude country_code  target_len  \n",
       "0  42.57688    1.66769           AD           8  \n",
       "1  42.57952    1.65362           AD          11  \n",
       "2  42.46372    1.49129           AD          21  \n",
       "3  42.54277    1.73361           AD          16  \n",
       "4  42.55623    1.53319           AD           8  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_raw.copy()\n",
    "\n",
    "df[TARGET_COL] = START_CHAR + df[TARGET_COL] + END_CHAR\n",
    "df[\"target_len\"] = df[TARGET_COL].apply(len)\n",
    "\n",
    "max_len = max([len(city) for city in df[TARGET_COL].values])\n",
    "df[TARGET_COL] = df[TARGET_COL].str.pad(max_len, side=\"right\", fillchar=PADDING_CHAR)\n",
    "\n",
    "chars = sorted(list(set(\"\".join(df[TARGET_COL].values))))\n",
    "vocab_len = len(chars)\n",
    "print(\"Vocabulary length:\", vocab_len)\n",
    "print(\"Vocabulary:\", \"\".join(chars))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded: [6, 26, 49, 46, 38, 39, 55, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Decoded: <Soldeu>##################################################\n"
     ]
    }
   ],
   "source": [
    "# Generate a mapping from character to index and vice versa\n",
    "char_to_idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx_to_char = {idx: char for idx, char in enumerate(chars)}\n",
    "\n",
    "encode = lambda x: [char_to_idx[char] for char in x]\n",
    "decode = lambda x: \"\".join([idx_to_char[idx] for idx in x])\n",
    "\n",
    "test_sample = df[TARGET_COL].values[0]\n",
    "print(\"Encoded:\", encode(test_sample))\n",
    "print(\"Decoded:\", decode(encode(test_sample)))\n",
    "\n",
    "START_TOKEN = encode(START_CHAR)[0]\n",
    "END_TOKEN = encode(END_CHAR)[0]\n",
    "PADDING_TOKEN = encode(PADDING_CHAR)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>asciiname</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>country_code</th>\n",
       "      <th>target_len</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Soldeu</td>\n",
       "      <td>&lt;Soldeu&gt;######################################...</td>\n",
       "      <td>42.57688</td>\n",
       "      <td>1.66769</td>\n",
       "      <td>AD</td>\n",
       "      <td>8</td>\n",
       "      <td>[6, 26, 49, 46, 38, 39, 55, 7, 1, 1, 1, 1, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>El Tarter</td>\n",
       "      <td>&lt;El Tarter&gt;###################################...</td>\n",
       "      <td>42.57952</td>\n",
       "      <td>1.65362</td>\n",
       "      <td>AD</td>\n",
       "      <td>11</td>\n",
       "      <td>[6, 12, 46, 0, 27, 35, 52, 54, 39, 52, 7, 1, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name                                          asciiname  latitude  \\\n",
       "0     Soldeu  <Soldeu>######################################...  42.57688   \n",
       "1  El Tarter  <El Tarter>###################################...  42.57952   \n",
       "\n",
       "   longitude country_code  target_len  \\\n",
       "0    1.66769           AD           8   \n",
       "1    1.65362           AD          11   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [6, 26, 49, 46, 38, 39, 55, 7, 1, 1, 1, 1, 1, ...  \n",
       "1  [6, 12, 46, 0, 27, 35, 52, 54, 39, 52, 7, 1, 1...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"tokenized\"] = df[TARGET_COL].apply(encode)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 173012\n"
     ]
    }
   ],
   "source": [
    "train_df = df.sample(frac=0.9, random_state=42)\n",
    "val_df = df.drop(train_df.index)\n",
    "print(\"Train size:\", len(train_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1121, 7)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df[val_df[\"country_code\"] == \"DE\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[45, 53, 39, 59, 39, 56, 53, 45],\n",
       "        [42, 39, 43, 38,  7,  1,  1,  1],\n",
       "        [41,  7,  1,  1,  1,  1,  1,  1],\n",
       "        [35, 48, 41,  7,  1,  1,  1,  1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[53, 39, 59, 39, 56, 53, 45, 35],\n",
       "        [39, 43, 38,  7,  1,  1,  1,  1],\n",
       "        [ 7,  1,  1,  1,  1,  1,  1,  1],\n",
       "        [48, 41,  7,  1,  1,  1,  1,  1]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(split, batch_size, block_size):\n",
    "    if split == \"train\":\n",
    "        df = train_df\n",
    "    elif split == \"val\":\n",
    "        df = val_df\n",
    "    x = []\n",
    "    y = []\n",
    "    sample_idx = torch.randint(0, len(df), (batch_size,))\n",
    "    for sidx in sample_idx:\n",
    "        target_len = df.iloc[int(sidx)][\"target_len\"]\n",
    "        max_idx = vocab_len - block_size - 3\n",
    "        idx = torch.randint(0, min(target_len - 1, max_idx), (1,)).int()\n",
    "        \n",
    "        x_tensor = torch.tensor(df.iloc[int(sidx)][\"tokenized\"][idx:idx+block_size])\n",
    "        y_tensor = torch.tensor(df.iloc[int(sidx)][\"tokenized\"][idx+1:idx+block_size+1])\n",
    "        x.append(x_tensor)\n",
    "        y.append(y_tensor)\n",
    "        \n",
    "    x = torch.stack(x)\n",
    "    y = torch.stack(y)\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch(\"train\", 4, 8)\n",
    "\n",
    "display(xb)\n",
    "display(yb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N Params: 209,213\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WherePT(\n",
       "  (token_embedding): Embedding(61, 64)\n",
       "  (position_embedding): Embedding(32, 64)\n",
       "  (blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-1): 2 x CausalSelfAttentionHead(\n",
       "            (query): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (key): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-1): 2 x CausalSelfAttentionHead(\n",
       "            (query): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (key): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-1): 2 x CausalSelfAttentionHead(\n",
       "            (query): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (key): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (sa): MultiHeadAttention(\n",
       "        (heads): ModuleList(\n",
       "          (0-1): 2 x CausalSelfAttentionHead(\n",
       "            (query): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (key): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (value): Linear(in_features=64, out_features=32, bias=False)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (proj): Linear(in_features=64, out_features=64, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ffwd): FeedForward(\n",
       "        (net): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "          (1): ReLU()\n",
       "          (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "          (3): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (ln1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (ln2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (ln_final): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): Linear(in_features=64, out_features=61, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 12\n",
    "\n",
    "mconf = wherept.WherePTConfig(\n",
    "    vocab_len=vocab_len,\n",
    "    n_embed=64,\n",
    "    n_head=2,\n",
    "    n_layer=4,\n",
    "    block_size=32,\n",
    "    dropout=0.1,\n",
    ")\n",
    "\n",
    "model = wherept.WherePT(mconf)\n",
    "\n",
    "# Print number of parameters:\n",
    "print(f\"N Params: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "\n",
    "xb, _ = get_batch(\"train\", BATCH_SIZE, mconf.block_size)\n",
    "#model_graph = draw_graph(model, input_data=xb)\n",
    "#model_graph.visual_graph\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVAL_ITERS = 10\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss(model):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(EVAL_ITERS)\n",
    "        for k in range(EVAL_ITERS):\n",
    "            X, Y = get_batch(split, BATCH_SIZE, mconf.block_size)\n",
    "            logits, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 3.0236, val loss 3.0024\n",
      "step 10: train loss 2.9965, val loss 3.0580\n",
      "step 20: train loss 3.0240, val loss 3.0356\n",
      "step 30: train loss 3.0596, val loss 3.0636\n",
      "step 40: train loss 3.0637, val loss 3.0410\n",
      "step 50: train loss 3.0254, val loss 3.0628\n",
      "step 60: train loss 3.0448, val loss 3.0730\n",
      "step 70: train loss 3.0916, val loss 3.0655\n",
      "step 80: train loss 3.0558, val loss 3.0189\n",
      "step 90: train loss 2.9539, val loss 3.0972\n",
      "step 99: train loss 3.0736, val loss 3.0096\n"
     ]
    }
   ],
   "source": [
    "MAX_ITERS = 100\n",
    "for iter in range(MAX_ITERS):\n",
    "    if iter % EVAL_ITERS == 0 or iter == MAX_ITERS - 1:\n",
    "        losses = estimate_loss(model)\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "    optimizer.zero_grad()\n",
    "    xb, yb = get_batch(\"train\", BATCH_SIZE, mconf.block_size)\n",
    "    logits, loss = model(xb, yb)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<plan>\n"
     ]
    }
   ],
   "source": [
    "idx = torch.tensor([START_TOKEN]).unsqueeze(0)\n",
    "#idx = torch.tensor(encode(\"<Stock\")).unsqueeze(0)\n",
    "\n",
    "output = model.generate(idx, max_len)[0].tolist()\n",
    "print(decode(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;pa&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Hee&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Vmr lniiCifnesa&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;VmGunaaspmulviesKrrn&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;u-n&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;Peo&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;Hgaaos&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;BsslnswqxdM&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;Teaeie&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;u bcana&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;h&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;ttlercsydnsBae&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;N&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;olrAleRsuahuats&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;yirPp pa&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;Srp&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;hll&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;Bne&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 generated\n",
       "0                     <pa>\n",
       "1                    <Hee>\n",
       "2        <Vmr lniiCifnesa>\n",
       "3   <VmGunaaspmulviesKrrn>\n",
       "4                    <u-n>\n",
       "5                       <>\n",
       "6                    <Peo>\n",
       "7                 <Hgaaos>\n",
       "8            <BsslnswqxdM>\n",
       "9                 <Teaeie>\n",
       "10                      <>\n",
       "11               <u bcana>\n",
       "12                     <h>\n",
       "13        <ttlercsydnsBae>\n",
       "14                     <N>\n",
       "15       <olrAleRsuahuats>\n",
       "16              <yirPp pa>\n",
       "17                   <Srp>\n",
       "18                   <hll>\n",
       "19                   <Bne>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples = [decode(model.generate(torch.tensor([START_TOKEN]).unsqueeze(0), 32)[0].tolist()) for _ in range(20)]\n",
    "examples = pd.DataFrame(examples, columns=[\"generated\"])\n",
    "examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unique-feather-13</strong> at: <a href='https://wandb.ai/lage/woher/runs/9gnefhgt' target=\"_blank\">https://wandb.ai/lage/woher/runs/9gnefhgt</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231202_151138-9gnefhgt/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "woher-wqR2TfXF-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
